{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkashKoley012/Deep-Learning-Projects/blob/main/Amazon%20Reviews%20for%20Sentiment%20Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b36a5666-900e-4acb-b9a4-5739b02cb85b",
      "metadata": {
        "id": "b36a5666-900e-4acb-b9a4-5739b02cb85b",
        "outputId": "e01cb8e6-393a-4397-fbab-f639a660a802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/bittlingmayer/amazonreviews\n",
            "License(s): unknown\n",
            "Downloading amazonreviews.zip to /content\n",
            "100% 493M/493M [00:21<00:00, 23.3MB/s]\n",
            "100% 493M/493M [00:21<00:00, 23.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d bittlingmayer/amazonreviews"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"amazonreviews.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "ELvTLZBIRJkc"
      },
      "id": "ELvTLZBIRJkc",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bz2\n",
        "import re\n",
        "import gc\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "S-mBxL1FSNyK"
      },
      "id": "S-mBxL1FSNyK",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Train & Test Files"
      ],
      "metadata": {
        "id": "NcYKknhVpI6-"
      },
      "id": "NcYKknhVpI6-"
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = bz2.BZ2File('/content/train.ft.txt.bz2')\n",
        "test_file = bz2.BZ2File('/content/test.ft.txt.bz2')"
      ],
      "metadata": {
        "id": "71j7h5MPRWeO"
      },
      "id": "71j7h5MPRWeO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Lists containing Train & Test sentences"
      ],
      "metadata": {
        "id": "t6Lf2sS9pOb0"
      },
      "id": "t6Lf2sS9pOb0"
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_lines = train_file.readlines()\n",
        "test_file_lines = test_file.readlines()\n",
        "\n",
        "del train_file, test_file"
      ],
      "metadata": {
        "id": "GaOp0K8USZmt"
      },
      "id": "GaOp0K8USZmt",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert from raw binary strings to strings that can be parsed"
      ],
      "metadata": {
        "id": "GV3BFQtQq26F"
      },
      "id": "GV3BFQtQq26F"
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
        "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
      ],
      "metadata": {
        "id": "_-iAxNGmSjfn"
      },
      "id": "_-iAxNGmSjfn",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file_lines]\n",
        "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file_lines]\n",
        "\n",
        "for i in range(len(train_sentences)):\n",
        "    train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n",
        "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
        "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])"
      ],
      "metadata": {
        "id": "XidT2s-urAq7"
      },
      "id": "XidT2s-urAq7",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file_lines]\n",
        "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file_lines]\n",
        "\n",
        "for i in range(len(test_sentences)):\n",
        "    test_sentences[i] = re.sub('\\d','0',test_sentences[i])\n",
        "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
        "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
      ],
      "metadata": {
        "id": "mXMIWqR0sB7G"
      },
      "id": "mXMIWqR0sB7G",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del train_file_lines, test_file_lines"
      ],
      "metadata": {
        "id": "qlwGIvm0seAP"
      },
      "id": "qlwGIvm0seAP",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "YjmqIm_8MiHx",
        "outputId": "6484cf43-f060-487c-fa43-64e424bb6953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YjmqIm_8MiHx",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "maxlen = 100"
      ],
      "metadata": {
        "id": "zpiFRSGlLee1"
      },
      "id": "zpiFRSGlLee1",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize"
      ],
      "metadata": {
        "id": "oB7Eh_lQLhYH"
      },
      "id": "oB7Eh_lQLhYH"
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('.','')\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "cpYkl8QzLhCN"
      },
      "id": "cpYkl8QzLhCN",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<UNK>':0}\n",
        "\n",
        "for sentence in train_sentences:\n",
        "  for word in tokenize(sentence):\n",
        "    if word not in vocab:\n",
        "      vocab[word] = len(vocab)"
      ],
      "metadata": {
        "id": "IIIhrWj_M3js"
      },
      "id": "IIIhrWj_M3js",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(seq, max_len=100):\n",
        "  return seq[:max_len] + [0] * (max_len - len(seq))"
      ],
      "metadata": {
        "id": "7n4TY7Y4NeYL"
      },
      "id": "7n4TY7Y4NeYL",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(sentence):\n",
        "  vector = []\n",
        "  for word in tokenize(sentence):\n",
        "    if word in vocab:\n",
        "      vector.append(vocab[word])\n",
        "    else:\n",
        "      vector.append(vocab['<UNK>'])\n",
        "  return pad_sequence(vector)"
      ],
      "metadata": {
        "id": "WAJAyxFdNpfm"
      },
      "id": "WAJAyxFdNpfm",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({'sentence':train_sentences, 'label':train_labels})\n",
        "test_df = pd.DataFrame({'sentence':test_sentences, 'label':test_labels})"
      ],
      "metadata": {
        "id": "vzS30Gxv-_Ae"
      },
      "id": "vzS30Gxv-_Ae",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df['sentence'] = train_df['sentence'].apply(vectorize)\n",
        "# test_df['sentence'] = test_df['sentence'].apply(vectorize)"
      ],
      "metadata": {
        "id": "w6QRzI1YOfps"
      },
      "id": "w6QRzI1YOfps",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset & DataLoader"
      ],
      "metadata": {
        "id": "5VFKiq-X_qVr"
      },
      "id": "5VFKiq-X_qVr"
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewsDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    feature = torch.tensor(vectorize(self.X[idx]), dtype=torch.long)\n",
        "    label = torch.tensor(self.y[idx], dtype=torch.long)\n",
        "    return feature, label"
      ],
      "metadata": {
        "id": "qMIyz7-B_TEd"
      },
      "id": "qMIyz7-B_TEd",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ReviewsDataset(train_df['sentence'], train_df['label'])\n",
        "test_dataset = ReviewsDataset(test_df['sentence'], test_df['label'])"
      ],
      "metadata": {
        "id": "ZcE6H7qR_6VF"
      },
      "id": "ZcE6H7qR_6VF",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "D5b6-2yJAUV3"
      },
      "id": "D5b6-2yJAUV3",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "wKJxpUxSAa3Q"
      },
      "id": "wKJxpUxSAa3Q"
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, 50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
        "    self.fc = nn.Linear(64, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    _, hidden = self.rnn(x)\n",
        "    x = self.fc(hidden.squeeze(0))\n",
        "    return x"
      ],
      "metadata": {
        "id": "c_Bm-QYoAd0c"
      },
      "id": "c_Bm-QYoAd0c",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Evaluation"
      ],
      "metadata": {
        "id": "tnZtPtwjAgXS"
      },
      "id": "tnZtPtwjAgXS"
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "wHxq4bfUAgHL"
      },
      "id": "wHxq4bfUAgHL",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = RNN(len(vocab)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "XU8pptZFAmAr",
        "outputId": "d0852154-48ce-478d-bcd7-466e9619ce03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XU8pptZFAmAr",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for feature, label in train_dataloader:\n",
        "    feature, label = feature.to(device), label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(feature)\n",
        "    loss = criterion(output, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f'Epoch: {epoch+1}, Loss: {total_loss/len(train_dataloader)}')"
      ],
      "metadata": {
        "id": "qMnZXcXRApdk",
        "outputId": "9aac0f9e-321c-4321-a992-e8c2da77b1b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "id": "qMnZXcXRApdk",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-aabd2da1f76f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch: {epoch+1}, Loss: {total_loss/len(train_dataloader)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for feature, label in test_dataloader:\n",
        "    feature, label = feature.to(device), label.to(device)\n",
        "    output = model(feature)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    total += label.size(0)\n",
        "    correct += (pred == label).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct/total}')"
      ],
      "metadata": {
        "id": "Sqzf2GDpAtBT"
      },
      "id": "Sqzf2GDpAtBT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for feature, label in train_dataloader:\n",
        "    feature, label = feature.to(device), label.to(device)\n",
        "    output = model(feature)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    total += label.size(0)\n",
        "    correct += (pred == label).sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct/total}')"
      ],
      "metadata": {
        "id": "x0m8tinHAvZW"
      },
      "id": "x0m8tinHAvZW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "",
      "name": ""
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}